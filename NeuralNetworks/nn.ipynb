{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "np.random.seed(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.2702, Accuracy: 0.3250\n",
      "Epoch 100, Loss: 0.9661, Accuracy: 0.7333\n",
      "Epoch 200, Loss: 0.7280, Accuracy: 0.8750\n",
      "Epoch 300, Loss: 0.5019, Accuracy: 0.9250\n",
      "Epoch 400, Loss: 0.3679, Accuracy: 0.9333\n",
      "Epoch 500, Loss: 0.2868, Accuracy: 0.9417\n",
      "Epoch 600, Loss: 0.2334, Accuracy: 0.9500\n",
      "Epoch 700, Loss: 0.1951, Accuracy: 0.9500\n",
      "Epoch 800, Loss: 0.1668, Accuracy: 0.9583\n",
      "Epoch 900, Loss: 0.1458, Accuracy: 0.9667\n",
      "Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes, learning_rate=0.1):\n",
    "        np.random.seed(42)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Initialize weights and biases for each layer\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.weights.append(np.random.randn(layer_sizes[i], layer_sizes[i+1]))\n",
    "            self.biases.append(np.zeros((1, layer_sizes[i+1])))\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def sigmoid_derivative(self, z):\n",
    "        return self.sigmoid(z) * (1 - self.sigmoid(z))\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp_values = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "        return exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "\n",
    "    def cross_entropy_loss(self, y_true, y_pred):\n",
    "        return -np.mean(np.sum(y_true * np.log(y_pred + 1e-9), axis=1))\n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        return np.mean(np.argmax(y_true, axis=1) == np.argmax(y_pred, axis=1))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.activations = [X]\n",
    "        self.z_values = []\n",
    "\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]\n",
    "            self.z_values.append(z)\n",
    "            a = self.sigmoid(z)\n",
    "            self.activations.append(a)\n",
    "\n",
    "        z = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]\n",
    "        self.z_values.append(z)\n",
    "        a = self.softmax(z)\n",
    "        self.activations.append(a)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def backward(self, y_true):\n",
    "        m = y_true.shape[0]\n",
    "        dA = self.activations[-1] - y_true\n",
    "\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            dZ = dA\n",
    "            if i != len(self.weights) - 1:\n",
    "                dZ = dA * self.sigmoid_derivative(self.z_values[i])\n",
    "            dW = np.dot(self.activations[i].T, dZ) / m\n",
    "            db = np.sum(dZ, axis=0, keepdims=True) / m\n",
    "\n",
    "            if i != 0:\n",
    "                dA = np.dot(dZ, self.weights[i].T)\n",
    "\n",
    "            self.weights[i] -= self.learning_rate * dW\n",
    "            self.biases[i] -= self.learning_rate * db\n",
    "\n",
    "    def train(self, X, y, epochs=1000):\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(X)\n",
    "            loss = self.cross_entropy_loss(y, y_pred)\n",
    "            self.backward(y)\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                acc = self.accuracy(y, y_pred)\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.forward(X)\n",
    "        return np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = data.target.reshape(-1, 1)  # Labels\n",
    "\n",
    "# One-hot encode the target\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the neural network with customizable layers\n",
    "layer_sizes = [X_train.shape[1], 10, 5, y_encoded.shape[1]]  # Example: 2 hidden layers\n",
    "nn = NeuralNetwork(layer_sizes=layer_sizes)\n",
    "nn.train(X_train, y_train, epochs=1000)\n",
    "\n",
    "# Test the neural network\n",
    "y_pred_test = nn.forward(X_test)\n",
    "test_acc = nn.accuracy(y_test, y_pred_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (150,4) and (150,10) not aligned: 4 (dim 1) != 150 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 66\u001b[0m, in \u001b[0;36mNN.train\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 66\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_entropy_loss(y, y_pred)\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(y)\n",
      "Cell \u001b[0;32mIn[19], line 35\u001b[0m, in \u001b[0;36mNN.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 35\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases[i]\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_values\u001b[38;5;241m.\u001b[39mappend(z)\n\u001b[1;32m     37\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(z)\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (150,4) and (150,10) not aligned: 4 (dim 1) != 150 (dim 0)"
     ]
    }
   ],
   "source": [
    "nn.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.9548, Accuracy: 0.3417\n",
      "Epoch 100, Loss: 0.9738, Accuracy: 0.8583\n",
      "Epoch 200, Loss: 0.7252, Accuracy: 0.8417\n",
      "Epoch 300, Loss: 0.5496, Accuracy: 0.8500\n",
      "Epoch 400, Loss: 0.4466, Accuracy: 0.9250\n",
      "Epoch 500, Loss: 0.3663, Accuracy: 0.9417\n",
      "Epoch 600, Loss: 0.2974, Accuracy: 0.9583\n",
      "Epoch 700, Loss: 0.2419, Accuracy: 0.9667\n",
      "Epoch 800, Loss: 0.2007, Accuracy: 0.9583\n",
      "Epoch 900, Loss: 0.1709, Accuracy: 0.9583\n",
      "Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = data.target.reshape(-1, 1)  # Labels\n",
    "\n",
    "# One-hot encode the target\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the neural network with customizable layers\n",
    "layer_sizes = [X_train.shape[1], 10, 10, 5, y_encoded.shape[1]]  # Example: 2 hidden layers\n",
    "nn = NeuralNetwork(layer_sizes=layer_sizes)\n",
    "nn.train(X_train, y_train, epochs=1000)\n",
    "\n",
    "# Test the neural network\n",
    "y_pred_test = nn.forward(X_test)\n",
    "test_acc = nn.accuracy(y_test, y_pred_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlscratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
